{"name":"Cousera machine learning project","tagline":"","body":"---\r\ntitle: \"Practical Machine Learning Course Project\"\r\nauthor: \"Katherine Tansey\"\r\n---\r\n\r\n# Background\r\n\r\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). \r\n\r\n\r\n# Load libraries and data\r\n\r\nLoad the R libraries needed for the analysis.\r\n\r\n```{r, results =FALSE}\r\nlibrary(AppliedPredictiveModeling)\r\nlibrary(caret)\r\nlibrary(ElemStatLearn) \r\nlibrary(pgmm)\r\nlibrary(rpart) \r\nlibrary(e1071)\r\nlibrary(randomForest)\r\nlibrary(rpart.plot)\t\t\t\r\nlibrary(RColorBrewer)\r\nlibrary(party)\t\t\t\t\r\nlibrary(partykit)\r\n\r\n```\r\n\r\nSet the seed for the analysis so it can be reproduced. \r\n\r\n```{r}\r\nset.seed(12345)\r\n```\r\n\r\nLoad in the data from the web. Check the size of the two datasets. \r\n\r\n```{r}\r\ntrainUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\r\nvalidationUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\r\ntraining <- read.csv(url(trainUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\r\nvalidation <- read.csv(url(validationUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\r\ndim(training)\r\ndim(validation)\r\n```\r\n\r\n\r\n# Split training dataset into two \r\n\r\nThe testing set will be the final set that we predict into, and so we will use it as a validation set (called validation). For this reason, we will split the training dataset into two, for training and testing the model we built. This will allow us to investigate the out of sample error rate of the model before we do the final prediction into the validation sets.  The training data is split into 70% training and 30% testing. \r\n\r\n```{r}\r\ninTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)\r\ntraining1 <- training[inTrain, ]\r\ntesting <- training[-inTrain, ]\r\ndim(training1) \r\ndim(testing)\r\n```\r\n\r\n# Clean the data \r\n\r\nAssess the data for the amount of missing (NA) values. \r\n\r\n```{r}\r\nna_test = sapply(training1, function(x) {sum(is.na(x))})\r\ntable(na_test)\r\n```\r\n\r\nThere are numerous variables without and missing, and then a lot of variables with almost all the data missing. Remove all variables with missing data, and just use the variables we have complete data on to build the model. \r\n\r\n```{r}\r\nbad_columns = names(na_test[na_test!=0])\r\ntraining1 = training1[, !names(training1) %in% bad_columns]\r\nstr(training1)\r\ndim(training1)\r\n```\r\n\r\nRemove the first seven columns of data. This information is about the person, time and other information that is not related to the movement. So remove these columns as they are not going to be used in the model.\r\n\r\n```{r}\r\ntraining1 = training1[,-c(1:7)]\r\n```\r\n\r\nCheck the data for variables that may have near zero variance. \r\n\r\n```{r}\r\nnzv_data <- nearZeroVar(training1, saveMetrics = TRUE)\r\ndim(nzv_data)\r\nnzv_data\r\n```\r\n\r\nNone of the remaining variables have near zero variance, so there is no need to remove variables for this reason. Our training dataset is now clean and ready to be used in model buliding. \r\n\r\n# Build model using RPART\r\n\r\nBuiliding a prediction model using recursive partitioning for classification algorithm (rpart).\r\n\r\n```{r}\r\nmodelRPART <- rpart(classe ~ ., data=training1, method=\"class\")\r\n```\r\n\r\nPredict into the testing dataset and see how well we are classifying movements in the new dataset. \r\n\r\n```{r}\r\npredictions <- predict(modelRPART, testing, type = \"class\")\r\nconfusionMatrix(predictions, testing$classe)\r\n```\r\n\r\nThe out-sample accuracy of the model is 71%, making the out-sample error rate 29%, which is high, and could be lower. Let's try out a different algorithm and see if the out-sample error rate can be reduced. \r\n\r\n\r\n# Build model using RandomForest\r\n\r\nSecond attempt will use the random forest algortihm to build the model. \r\n\r\n```{r}\r\nmodelRF <- randomForest(classe ~. , data=training1)\r\n```\r\n\r\nPredict into the testing dataset and see how well we are classifying movements in the new dataset.\r\n\r\n```{r}\r\npredictionsRF <- predict(modelRF, testing, type = \"class\")\r\nconfusionMatrix(predictionsRF, testing$classe)\r\n```\r\n\r\nThe out-sample accuracy of the model is 99.52%, making the out-sample error rate 0.48%, which implies the sample is doing really well in classifying the data. This model is performing much better than the previous one. We will use this model for predicting into the validation set. \r\n\r\n# Validation Prediction\r\n\r\nIn the final step, the validation data and the randomforest model will be used to predict movements. \r\n\r\n```{r}\r\npredictions_final <- predict(modelRF, validation, type = \"class\")\r\n```\r\n\r\nThe code below uploads the information to Coursera\r\n\r\n```{r}\r\npml_write_files = function(x){\r\n  n = length(x)\r\n  for(i in 1:n){\r\n    filename = paste0(\"problem_id_\",i,\".txt\")\r\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\r\n  }\r\n}\r\n\r\npml_write_files(predictions_final)\r\n```\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}