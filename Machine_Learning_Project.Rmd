---
title: "Practical Machine Learning Course Project"
author: "Katherine Tansey"
output: html_document
---

# Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 


# Load libraries and data

Load the R libraries needed for the analysis.

```{r, results =FALSE}
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn) 
library(pgmm)
library(rpart) 
library(e1071)
library(randomForest)
library(rpart.plot)			
library(RColorBrewer)
library(party)				
library(partykit)

```

Set the seed for the analysis so it can be reproduced. 

```{r}
set.seed(12345)
```

Load in the data from the web. Check the size of the two datasets. 

```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
validationUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
validation <- read.csv(url(validationUrl), na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(validation)
```


# Split training dataset into two 

The testing set will be the final set that we predict into, and so we will use it as a validation set (called validation). For this reason, we will split the training dataset into two, for training and testing the model we built. This will allow us to investigate the out of sample error rate of the model before we do the final prediction into the validation sets.  The training data is split into 70% training and 30% testing. 

```{r}
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
training1 <- training[inTrain, ]
testing <- training[-inTrain, ]
dim(training1) 
dim(testing)
```

# Clean the data 

Assess the data for the amount of missing (NA) values. 

```{r}
na_test = sapply(training1, function(x) {sum(is.na(x))})
table(na_test)
```

There are numerous variables without and missing, and then a lot of variables with almost all the data missing. Remove all variables with missing data, and just use the variables we have complete data on to build the model. 

```{r}
bad_columns = names(na_test[na_test!=0])
training1 = training1[, !names(training1) %in% bad_columns]
str(training1)
dim(training1)
```

Remove the first seven columns of data. This information is about the person, time and other information that is not related to the movement. So remove these columns as they are not going to be used in the model.

```{r}
training1 = training1[,-c(1:7)]
```

Check the data for variables that may have near zero variance. 

```{r}
nzv_data <- nearZeroVar(training1, saveMetrics = TRUE)
dim(nzv_data)
nzv_data
```

None of the remaining variables have near zero variance, so there is no need to remove variables for this reason. Our training dataset is now clean and ready to be used in model buliding. 

# Build model using RPART

Builiding a prediction model using recursive partitioning for classification algorithm (rpart).

```{r}
modelRPART <- rpart(classe ~ ., data=training1, method="class")
```

Predict into the testing dataset and see how well we are classifying movements in the new dataset. 

```{r}
predictions <- predict(modelRPART, testing, type = "class")
confusionMatrix(predictions, testing$classe)
```

The out-sample accuracy of the model is 71%, making the out-sample error rate 29%, which is high, and could be lower. Let's try out a different algorithm and see if the out-sample error rate can be reduced. 


# Build model using RandomForest

Second attempt will use the random forest algortihm to build the model. 

```{r}
modelRF <- randomForest(classe ~. , data=training1)
```

Predict into the testing dataset and see how well we are classifying movements in the new dataset.

```{r}
predictionsRF <- predict(modelRF, testing, type = "class")
confusionMatrix(predictionsRF, testing$classe)
```

The out-sample accuracy of the model is 99.52%, making the out-sample error rate 0.48%, which implies the sample is doing really well in classifying the data. This model is performing much better than the previous one. We will use this model for predicting into the validation set. 

# Validation Prediction

In the final step, the validation data and the randomforest model will be used to predict movements. 

```{r}
predictions_final <- predict(modelRF, validation, type = "class")
```

The code below uploads the information to Coursera

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions_final)
```


